{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format to specify is the one from thermonet\n",
    "# needs to bee: P03958A 263 W F\n",
    "# ie: uniprot+mutated_chain mutation_position wild_aa mutated_aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_INPUT = \"../data/main_dataset_creation/outputs/merged/dataset_with_3D_paths.csv\"\n",
    "SUBMISSION_INPUT = \"../data/processed_test.csv\"\n",
    "COMPUTE_NEW_MUTATIONS_LISTS = True\n",
    "CLEAN_MUTATIONS = True\n",
    "GET_ALREADY_COMPUTED = False\n",
    "\n",
    "ROSETTA_BIN_DIR_PARIS = \"/home/ml/novozymes-prediction/resources/rosetta/rosetta_bin_linux_2021.16.61629_bundle/main/source/bin/\"\n",
    "ROSETTA_BIN_DIR_GCP = \"/home/jupyter/novozymes-prediction/resources/rosetta_bin_linux_2021.16.61629_bundle/main/source/bin/\"\n",
    "ROSETTA_BIN_DIR_SOUTH = \"/home/tom/Documents/Kaggle/novozymes-prediction/resources/rosetta_bin_linux_2021.16.61629_bundle/main/source/bin/\"\n",
    "RELAX_BIN_PARIS = f\"{ROSETTA_BIN_DIR_PARIS}relax.static.linuxgccrelease\"\n",
    "RELAX_BIN_GCP = f\"{ROSETTA_BIN_DIR_GCP}relax.static.linuxgccrelease\"\n",
    "RELAX_BIN_SOUTH = f\"{ROSETTA_BIN_DIR_SOUTH}relax.static.linuxgccrelease\"\n",
    "THREADS_GCP = 32 # 32 max\n",
    "THREADS_PARIS = 0 # 12 max\n",
    "THREADS_SOUTH = 6 # 8 max\n",
    "THREADS = THREADS_PARIS+THREADS_SOUTH+THREADS_GCP\n",
    "GCP_RATIO = THREADS_GCP/THREADS\n",
    "PARIS_RATIO = THREADS_PARIS/THREADS\n",
    "DDG_ONLY = False\n",
    "SUBSET_DUPLICATES_NO_PH = [\"uniprot\", \"wild_aa\", \"mutation_position\",\n",
    "                           \"mutated_aa\", \"sequence\"]\n",
    "MAX_PROTEIN_SIZE = 600\n",
    "MAX_CONSECUTIVE_TASKS = 100\n",
    "\n",
    "COMPUTE_SUBMISSION = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8165\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(DATASET_INPUT)\n",
    "df_train = df_train[~(df_train.alphafold_path.isna())]\n",
    "if DDG_ONLY:\n",
    "    df_train = df_train[~(df_train.ddG.isna())]\n",
    "df_train.drop_duplicates(subset=SUBSET_DUPLICATES_NO_PH, inplace=True)\n",
    "df_train[\"already_computed\"] = False\n",
    "df_train = df_train[SUBSET_DUPLICATES_NO_PH +\n",
    "                    [\"already_computed\", \"alphafold_path\", \"mutated_chain\"]]\n",
    "# limit to protein with a sequence not too long\n",
    "df_train[\"length\"] = df_train.sequence.str.len()\n",
    "df_train = df_train[df_train[\"length\"].le(MAX_PROTEIN_SIZE)]\n",
    "\n",
    "if COMPUTE_SUBMISSION:\n",
    "    df_test = pd.read_csv(SUBMISSION_INPUT)\n",
    "    df_test.drop_duplicates(subset=SUBSET_DUPLICATES_NO_PH, inplace=True)\n",
    "    df_test[\"already_computed\"] = False\n",
    "    df_test = df_test[SUBSET_DUPLICATES_NO_PH +\n",
    "                    [\"already_computed\", \"alphafold_path\", \"mutated_chain\"]]\n",
    "    #rm deletion\n",
    "    df_test = df_test[~(df_test.mutated_aa.eq('-'))]   \n",
    "    df = pd.concat([df_train, df_test])\n",
    "else:\n",
    "    df = df_train\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "406\n",
      "404\n"
     ]
    }
   ],
   "source": [
    "print(len(df.uniprot.unique()))\n",
    "print(len(df.alphafold_path.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CLEAN_MUTATIONS:\n",
    "    for path in glob(\"./mutations/*\"):\n",
    "        os.remove(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "['Q15562_relaxed', 'Q04206_relaxed', 'P36075_relaxed', 'P0306_relaxed', 'P38398_relaxed', 'P21695_relaxed', 'O25949_relaxed', 'P61769_relaxed', 'P01051_relaxed', 'P0CG63_relaxed', 'P25963_relaxed', 'A8T655_relaxed', 'P01053_relaxed', 'P0C0Y9_relaxed', 'P06876_relaxed', 'P01837_relaxed', 'P00766_relaxed', 'P04080_relaxed', 'P01308_relaxed', 'Q8NBP7_relaxed', 'Q03026_relaxed', 'P03958_relaxed', 'P07320_relaxed']\n"
     ]
    }
   ],
   "source": [
    "crashed_backup = ['Q15562_relaxed', 'Q04206_relaxed', 'P0306_relaxed', 'P38398_relaxed', 'P21695_relaxed',\n",
    "                  'P61769_relaxed', 'P01051_relaxed', 'P0CG63_relaxed', 'P25963_relaxed',\n",
    "                  'A8T655_relaxed', 'P01053_relaxed', 'P06876_relaxed', 'P04080_relaxed', 'P01308_relaxed',\n",
    "                  'Q8NBP7_relaxed', 'Q03026_relaxed', 'P03958_relaxed', 'P07320_relaxed']\n",
    "crashed = glob(\"relaxed_pdb/**/*CRASH*\")\n",
    "crashed = [n.split('/')[-2] for n in crashed]\n",
    "crashed.pop(crashed.index(\"AF70_relaxed\"))\n",
    "print(len(crashed))\n",
    "print(crashed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "divided P06654 related_df into 1 subdf\n",
      "divided P06241 related_df into 1 subdf\n",
      "divided P00720 related_df into 1 subdf\n",
      "divided D4Z2G1 related_df into 1 subdf\n",
      "divided P63096 related_df into 1 subdf\n",
      "1149\n"
     ]
    }
   ],
   "source": [
    "if COMPUTE_NEW_MUTATIONS_LISTS:\n",
    "    already_computed = glob(\"relaxed_pdb/**/*_relaxed*_relaxed.pdb\")\n",
    "    \n",
    "    already_computed = [n.split('/')[-1] for n in already_computed]\n",
    "    total_to_compute = 0\n",
    "\n",
    "    for alphafold_path in df.alphafold_path.unique():\n",
    "        alphafold_name = os.path.splitext(\n",
    "            alphafold_path.split('/')[-1])[0]\n",
    "        if f\"{alphafold_name}_relaxed\" in crashed:\n",
    "            continue\n",
    "            \n",
    "        related_df = df[df.alphafold_path.eq(alphafold_path)]\n",
    "\n",
    "        def rm_already_computed(row):\n",
    "            alphafold_name = os.path.splitext(\n",
    "                row[\"alphafold_path\"].split('/')[-1])[0]\n",
    "            output_name = f\"{alphafold_name}_relaxed_{row['wild_aa']}{int(row['mutation_position']+1)}{row['mutated_aa']}_relaxed.pdb\"\n",
    "            if output_name in already_computed:\n",
    "                row[\"already_computed\"] = True\n",
    "            return row\n",
    "\n",
    "        related_df = related_df.apply(rm_already_computed, axis=1)\n",
    "        related_df = related_df[~(related_df[\"already_computed\"])]\n",
    "\n",
    "        if len(related_df) > MAX_CONSECUTIVE_TASKS:\n",
    "            # in the case of a protein with a lot of related mutation we split it into THREADS sub_subdf\n",
    "            number_splits = min(THREADS, len(related_df)//MAX_CONSECUTIVE_TASKS)\n",
    "            subdf_list = [related_df.iloc[index, :]\n",
    "                          for index in np.array_split(range(len(related_df)), number_splits)]\n",
    "            print(f\"divided {alphafold_name} related_df into {len(subdf_list)} subdf\")\n",
    "        else:\n",
    "            subdf_list = [related_df]\n",
    "        \n",
    "        for i, subdf in enumerate(subdf_list):\n",
    "            # create the mutation list from the sub df that contains the alphafold_path\n",
    "            for _, row in subdf.iterrows():\n",
    "                # we add 1 to the position as we index starting at 0 and rosetta at 1\n",
    "                with open(f\"mutations/{alphafold_name}_{i}.txt\", \"a+\") as f:\n",
    "                    line = f\"{alphafold_name}{row['mutated_chain']} {int(row['mutation_position']+1)} {row['wild_aa']} {row['mutated_aa']}\"\n",
    "                    f.write(line)\n",
    "                    f.write(\"\\n\")\n",
    "                total_to_compute += 1\n",
    "    print(total_to_compute)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64, GCP_index=53, PARIS_index=53\n"
     ]
    }
   ],
   "source": [
    "# split mutations lists between CPUs\n",
    "mutations_lists = glob(\"mutations/*.txt\")\n",
    "GCP_index = int(len(mutations_lists)*GCP_RATIO)\n",
    "PARIS_index = GCP_index+int(len(mutations_lists)*PARIS_RATIO)\n",
    "mutations_GCP = mutations_lists[:GCP_index]\n",
    "mutations_PARIS = mutations_lists[GCP_index:PARIS_index]\n",
    "mutations_SOUTH = mutations_lists[PARIS_index:]\n",
    "print(f\"{len(mutations_lists)}, {GCP_index=}, {PARIS_index=}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bash scripts\n",
    "for i, mutations_list in enumerate(mutations_GCP):\n",
    "    script_suffix = f\"GCP_{i % THREADS_GCP}\"\n",
    "    name, _ = os.path.splitext(mutations_list.split(\"/\")[-1])\n",
    "    with open(f\"mutations_{script_suffix}.sh\", \"a+\") as f:\n",
    "        cmd = f\"python3 rosetta_relax.py --rosetta-bin {RELAX_BIN_GCP} -l {mutations_list} --base-dir ./relaxed_pdb/ > {name}.log\"\n",
    "        f.write(cmd)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "for i, mutations_list in enumerate(mutations_PARIS):\n",
    "    script_suffix = f\"PARIS_{i % THREADS_PARIS}\"\n",
    "    name, _ = os.path.splitext(mutations_list.split(\"/\")[-1])\n",
    "    with open(f\"mutations_{script_suffix}.sh\", \"a+\") as f:\n",
    "        cmd = f\"python3 rosetta_relax.py --rosetta-bin {RELAX_BIN_PARIS} -l {mutations_list} --base-dir ./relaxed_pdb/ > {name}.log\"\n",
    "        f.write(cmd)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "for i, mutations_list in enumerate(mutations_SOUTH):\n",
    "    name, _ = os.path.splitext(mutations_list.split(\"/\")[-1])\n",
    "    script_suffix = f\"SOUTH_{i % THREADS_SOUTH}\"\n",
    "    with open(f\"mutations_{script_suffix}.sh\", \"a+\") as f:\n",
    "        cmd = f\"python3 rosetta_relax.py --rosetta-bin {RELAX_BIN_SOUTH} -l {mutations_list} --base-dir ./relaxed_pdb/ > {name}.log\"\n",
    "        f.write(cmd)\n",
    "        f.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"main_mutations_GCP.sh\", \"w+\") as f:\n",
    "    for i in range(THREADS_GCP):\n",
    "        f.write(f\"bash mutations_GCP_{i}.sh & \\n\")\n",
    "\n",
    "with open(\"main_mutations_PARIS.sh\", \"w+\") as f:\n",
    "    for i in range(THREADS_PARIS):\n",
    "        f.write(f\"bash mutations_PARIS_{i}.sh & \\n\")\n",
    "\n",
    "with open(\"main_mutations_SOUTH.sh\", \"w+\") as f:\n",
    "    for i in range(THREADS_SOUTH):\n",
    "        f.write(f\"bash mutations_SOUTH_{i}.sh & \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
