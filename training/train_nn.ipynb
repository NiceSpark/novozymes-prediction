{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training of Neural Network for Novozyme Prediction\n",
    "This NB allows you to test a NN model and get training infos\n",
    "The different parts are:\n",
    "- Simple train: train a NN based on the parameters in the config file\n",
    "- Compute learning curve: mse for a dataset of 100/1000/3000/all rows\n",
    "- Compute feature importance: use saved models and scalers to compute the avg mse with each features being randomized one at a time\n",
    "- Compute submission: use saved models and scalers to compute the avg mse for each row of the submission dataset\n",
    "\n",
    "Note: for hyper parameters optimization see the wandb_training.py script, in which we use wandb to sweep through a list of posssible hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from training_utils.file_utils import (open_json, write_json, save_submission,\n",
    "                                       log_kfold_training, log_learning_curve)\n",
    "from training_utils.models import SimpleNN\n",
    "from training_utils.model_utils import *\n",
    "from training_utils.training import train_model, k_fold_training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = open_json(\"simple_nn_config.json\")\n",
    "features_dict = open_json(f\"{config['dataset_dir']}/features.json\")\n",
    "features, features_infos = compute_feature_list(config, features_dict)\n",
    "\n",
    "LOG_NAME = \"SimpleNN\"\n",
    "KEEP_MODELS = True\n",
    "\n",
    "SIMPLE_TRAIN = True\n",
    "COMPUTE_LEARNING_CURVE = False\n",
    "COMPUTE_FEATURE_IMPORTANCE = False\n",
    "COMPUTE_SUBMISSION = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available() and config[\"use_cuda\"]:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SIMPLE_TRAIN:\n",
    "    df = load_dataset(config, features)\n",
    "\n",
    "    all_training_results = {\"simple_train\": [],\n",
    "                            \"total_training_time\": 0}\n",
    "    print(f\"{type(all_training_results)=}\")\n",
    "\n",
    "    # add protein_index to the dataset and get ksplit:\n",
    "    df = split_dataset(df, config)\n",
    "    training_results, model_list, scaler_list = k_fold_training(\n",
    "        df, config, features, features_infos, device, keep_models=KEEP_MODELS)\n",
    "\n",
    "    # add training results to all the other ones\n",
    "    all_training_results[\"simple_train\"] = training_results\n",
    "    print(f\"{type(all_training_results)=}\")\n",
    "    # compute avg_mse and time\n",
    "    train_mse = sum(x[\"train_mse\"]\n",
    "                    for x in training_results)/config[\"kfold\"]\n",
    "    test_mse = sum(x[\"test_mse\"]\n",
    "                   for x in training_results)/config[\"kfold\"]\n",
    "    training_time = sum(x[\"time\"] for x in training_results)\n",
    "\n",
    "    # save results to output\n",
    "    model = SimpleNN(\n",
    "        len(features_infos[\"direct_features\"]), config)\n",
    "    model_structure = str(model).replace('(', '').replace(')', '').split('\\n')\n",
    "    dir_path = log_kfold_training(\n",
    "        LOG_NAME, all_training_results, config, features, model_structure)\n",
    "        \n",
    "    if KEEP_MODELS:\n",
    "        save_models_and_scalers(dir_path, model_list, scaler_list)\n",
    "        \n",
    "    print(f\"{type(all_training_results)=}\")\n",
    "    print(f\"logged training in {dir_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find worst samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SIMPLE_TRAIN:\n",
    "    WORST_SAMPLES_DIFF_THRESHOLD = 10\n",
    "    worst_of_the_worst = []\n",
    "    # WORST_SAMPLES_DIFF_THRESHOLD = 1\n",
    "    for res in all_training_results.get(\"simple_train\"):\n",
    "        worst_samples = res.get(\"worst_samples\")\n",
    "        worst_of_the_worst += [record for record in worst_samples if record[\"diff\"]\n",
    "                               > WORST_SAMPLES_DIFF_THRESHOLD]\n",
    "\n",
    "    print(len(worst_of_the_worst))\n",
    "    write_json(\"worst_samples.json\", worst_of_the_worst)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COMPUTE_LEARNING_CURVE:\n",
    "    df = load_dataset(config, features)\n",
    "\n",
    "    # plot the learning curve of the model\n",
    "    # ie. the avg mse when df has 10, 100, 1000 elements\n",
    "    # len(df) = 5k\n",
    "    num_rows = [100, 1000, 3000, len(df)]\n",
    "    all_training_results = {\"training_by_num_rows\": [],\n",
    "                            \"learning_curve\": {\"num_rows\": num_rows,\n",
    "                                               \"train_mse\": [],\n",
    "                                               \"test_mse\": []\n",
    "                                               },\n",
    "                            \"total_training_time\": 0\n",
    "                            }\n",
    "\n",
    "    t0 = time.time()\n",
    "    for n in num_rows:\n",
    "        print(f\"training on {n} rows from the dataset\")\n",
    "        df_n_rows = df.sample(n)\n",
    "        # add protein_index to the dataset and get ksplit:\n",
    "        df_n_rows, ksplit = split_dataset(df_n_rows, config)\n",
    "        training_results, _, _ = k_fold_training(\n",
    "            df_n_rows, ksplit, config, features, features_infos, device)\n",
    "\n",
    "        # add training results to all the other ones\n",
    "        all_training_results[\"training_by_num_rows\"].append(training_results)\n",
    "        # compute avg_mse and time\n",
    "        train_mse = sum(x[\"train_mse\"]\n",
    "                        for x in training_results)/config[\"kfold\"]\n",
    "        test_mse = sum(x[\"test_mse\"]\n",
    "                       for x in training_results)/config[\"kfold\"]\n",
    "        training_time = sum(x[\"time\"] for x in training_results)\n",
    "\n",
    "        # update result variables\n",
    "        all_training_results[\"total_training_time\"] += training_time\n",
    "        all_training_results[\"learning_curve\"][\"train_mse\"].append(train_mse)\n",
    "        all_training_results[\"learning_curve\"][\"test_mse\"].append(test_mse)\n",
    "\n",
    "    total_time = time.time()-t0\n",
    "    print(f\"total_training_time= {all_training_results['total_training_time']:.2f}, {total_time= :.2f}, \\\n",
    "        training_time: {(all_training_results['total_training_time']/total_time)*100:.2f}% of total time\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COMPUTE_LEARNING_CURVE:\n",
    "    # save results to output\n",
    "    model = SimpleNN(\n",
    "        len(features_infos[\"direct_features\"]), config)\n",
    "    model_structure = str(model).replace('(', '').replace(')', '').split('\\n')\n",
    "    dir_path = log_learning_curve(\n",
    "        LOG_NAME, all_training_results, config, features, model_structure)\n",
    "    print(f\"logged training in {dir_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COMPUTE_FEATURE_IMPORTANCE:\n",
    "    # all_training_results[feature1]: result obtained when df[feature1] = random\n",
    "    all_training_results = {}\n",
    "\n",
    "    df = load_dataset(config, features)\n",
    "\n",
    "    # 1. we train kfold models using all features:\n",
    "    df = split_dataset(df, config)\n",
    "    training_results, model_list, scaler_list = k_fold_training(\n",
    "        df, config, features, features_infos, device, keep_models=True)\n",
    "\n",
    "    # compute mse (with no feature randomized)\n",
    "    none_random_train_mse = sum(x['train_mse']\n",
    "                                for x in training_results)/config['kfold']\n",
    "    none_random_test_mse = sum(x['test_mse']\n",
    "                               for x in training_results)/config['kfold']\n",
    "    all_training_results[\"none_randomized\"] = {\n",
    "        \"train_mse\": none_random_train_mse, \"test_mse\": none_random_test_mse}\n",
    "\n",
    "    # 2. for each feature we take the df, randomize the feature column, then compute the new mse score with each model\n",
    "    print(\"now testing with random features\")\n",
    "    for feature in features:\n",
    "        # create a copy of the dataset with the feature column being random\n",
    "        df_random = copy.deepcopy(df)\n",
    "        df_random[feature] = np.random.uniform(\n",
    "            low=df[feature].min(), high=df[feature].max(), size=df_random.shape[0])\n",
    "        training_results = []\n",
    "\n",
    "        # evaluate all model on this new dataset\n",
    "        for k in range(config[\"kfold\"]):\n",
    "            # we get the same ksplit as during training as we already added the kfold column to df\n",
    "            train = list(range(config[\"kfold\"]))\n",
    "            test = [train.pop(k)]\n",
    "            df_train = df_random[df_random[\"kfold\"].isin(train)]\n",
    "            df_test = df_random[df_random[\"kfold\"].isin(test)]\n",
    "            model = model_list[k]  # model result from the training\n",
    "            dataset_train_scaler = scaler_list[k]  # scaler from training\n",
    "\n",
    "            # we load the data for evaluation\n",
    "            X_train, y_train = prepare_eval_data(\n",
    "                df_train, config, features, features_infos, dataset_train_scaler)\n",
    "            X_test, y_test = prepare_eval_data(\n",
    "                df_test, config, features, features_infos, dataset_train_scaler)\n",
    "\n",
    "            # Evaluate this model:\n",
    "            model.eval()\n",
    "            with torch.set_grad_enabled(False):\n",
    "                train_mse, _ = evaluate_model(X_train, y_train, model, device)\n",
    "                test_mse, _ = evaluate_model(X_test, y_test, model, device)\n",
    "                # print(f\"MSE obtained for kfold {k}: {mse}\")\n",
    "                results = {\n",
    "                    \"train_mse\": train_mse,\n",
    "                    \"test_mse\": test_mse\n",
    "                }\n",
    "                training_results.append(results)\n",
    "\n",
    "        # compute avg_mse\n",
    "        train_mse = sum(x['train_mse']\n",
    "                        for x in training_results)/config['kfold']\n",
    "        test_mse = sum(x['test_mse']\n",
    "                       for x in training_results)/config['kfold']\n",
    "        # add training results to all the other ones\n",
    "        all_training_results[feature] = {\n",
    "            \"train_mse\": train_mse, \"test_mse\": test_mse,\n",
    "            \"delta_train_mse\": train_mse-none_random_train_mse,\n",
    "            \"delta_test_mse\": test_mse-none_random_test_mse,\n",
    "        }\n",
    "\n",
    "    # rank results\n",
    "    ranked_delta_test_mse = [[x, all_training_results[x].get(\n",
    "        \"delta_test_mse\", 0)] for x in all_training_results.keys()]\n",
    "    ranked_delta_test_mse.sort(key=lambda x: x[1], reverse=True)\n",
    "    ranked_delta_test_mse = {x[0]: x[1] for x in ranked_delta_test_mse}\n",
    "    write_json(f\"./outputs/{LOG_NAME}_feature_importance.json\",\n",
    "               {\"ranked_delta_test_mse\": ranked_delta_test_mse,\n",
    "                \"all_training_results\": all_training_results})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting on submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   seq_id        tm\n",
      "0   31390  0.032039\n",
      "1   31391 -0.036185\n",
      "2   31392 -0.989702\n",
      "3   31393 -0.371179\n",
      "4   31394 -0.264186\n",
      "save_path='./submissions/SimpleNN_2022-11-25_15-33-56.csv'\n"
     ]
    }
   ],
   "source": [
    "if COMPUTE_SUBMISSION:\n",
    "    dir_path = \"outputs/SimpleNN_11/\"\n",
    "    df_test = pd.read_csv(\n",
    "        f\"{config['dataset_dir']}/submission_all_features_filled_nan.csv\")\n",
    "    results = []\n",
    "\n",
    "    model_list, scaler_list = load_models_and_scalers(dir_path)\n",
    "\n",
    "    for k in range(len(model_list)):\n",
    "        X_test = df_test[features].copy()\n",
    "\n",
    "        model = model_list[k]  # model result from the training\n",
    "        dataset_train_scaler = scaler_list[k]  # scaler from training\n",
    "\n",
    "        # Evaluate this model:\n",
    "        model.eval()\n",
    "        with torch.set_grad_enabled(False):\n",
    "            X_test = dataset_train_scaler.transform(X_test)\n",
    "            X_test = X_test[:, features_infos[\"direct_features\"]]\n",
    "\n",
    "            X_test = torch.from_numpy(X_test)\n",
    "            X_test = X_test.to(device)\n",
    "            y_test = model(X_test)\n",
    "            results.append(y_test.detach().numpy())\n",
    "\n",
    "    submission = pd.DataFrame(columns=[\"seq_id\", \"tm\"])\n",
    "    submission[\"seq_id\"] = df_test[\"seq_id\"]\n",
    "    submission[\"tm\"] = np.mean(np.array(results), axis=0)\n",
    "    print(submission.head())\n",
    "    save_path = save_submission(submission, LOG_NAME)\n",
    "    print(f\"{save_path=}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
