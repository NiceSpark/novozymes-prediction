{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset creation\n",
    "\n",
    "![flowchart](./resources/dataset_creation_flowchart.drawio.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from utils.file_utils import open_json, write_json\n",
    "from utils.dataset_creation import *\n",
    "from utils.dataset_mapping import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRESH_START = True\n",
    "UPDATE_MAPPING = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS = [\"pdbs\", \"uniprot\", \"wild_aa\", \"mutation_position\",\n",
    "           \"mutated_aa\", \"pH\",\n",
    "           \"sequence\", \"length\", \"chain_start\", \"chain_end\",\n",
    "           \"AlphaFoldDB\", \"Tm\", \"ddG\", \"dTm\",\n",
    "           \"dataset_source\", \"infos_found\"]\n",
    "\n",
    "SUBSET_DUPLICATES = [\"uniprot\", \"wild_aa\", \"mutation_position\",\n",
    "                     \"mutated_aa\", \"pH\", \"sequence\"]\n",
    "\n",
    "OUPUT_DIR = \"./data/main_dataset_creation\"\n",
    "LOCAL_UNIPROT_INFOS_PATH = OUPUT_DIR+\"/uniprot_infos.json\"\n",
    "PDB_UNIPROT_MAPPING_PATH = OUPUT_DIR+\"/mapping/pdb_uniprot_mapping.json\"\n",
    "LINKED_UNIPROT_MAPPING_PATH = OUPUT_DIR+\"/mapping/linked_uniprot_mapping.json\"\n",
    "SEQUENCE_UNIPROT_MAPPING_PATH = OUPUT_DIR + \\\n",
    "    \"/mapping/sequence_uniprot_mapping.json\"\n",
    "PDB_NO_UNIPROT_PATH = OUPUT_DIR+\"/mapping/pdb_no_uniprot.json\"\n",
    "SEQUENCE_NO_UNIPROT_PATH = OUPUT_DIR+\"/mapping/sequence_no_uniprot.json\"\n",
    "\n",
    "DATASET_OUTPUT_PATH_RAW = OUPUT_DIR+\"/dataset_raw.csv\"\n",
    "DATASET_OUTPUT_PATH_ONLY_INFOS = OUPUT_DIR+\"/dataset_only_infos.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infos for dataset creation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 549 uniprot infos from local storage\n"
     ]
    }
   ],
   "source": [
    "local_uniprot_infos = open_json(LOCAL_UNIPROT_INFOS_PATH)\n",
    "dataset_config = open_json(OUPUT_DIR+\"/dataset_config.json\")\n",
    "\n",
    "print(f\"loaded {len(local_uniprot_infos)} uniprot infos from local storage\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/ProThermDB/processed_prothermdb.csv\")\n",
    "df.mutation_code.isna().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### FireProtDB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed fireprotdb:\n",
      "errors={'no_sequence_in_data': 0, 'not_in_local': 0, 'wrong_position': 222, 'no_uniprot': 0, 'no_pdb': 0, 'no_sequence': 0}\n",
      "\n",
      "11201\n",
      "processed thermomutdb:\n",
      "errors={'no_sequence_in_data': 0, 'not_in_local': 0, 'wrong_position': 2651, 'no_uniprot': 0, 'no_pdb': 0, 'no_sequence': 0}\n",
      "\n",
      "processed O2567_new:\n",
      "errors={'no_sequence_in_data': 0, 'not_in_local': 0, 'wrong_position': 0, 'no_uniprot': 0, 'no_pdb': 0, 'no_sequence': 0}\n",
      "\n",
      "processed prothermdb:\n",
      "errors={'no_sequence_in_data': 0, 'not_in_local': 0, 'wrong_position': 1451, 'no_uniprot': 0, 'no_pdb': 0, 'no_sequence': 0}\n",
      "\n",
      "processed jinyuan_sun_train:\n",
      "errors={'no_sequence_in_data': 0, 'not_in_local': 0, 'wrong_position': 0, 'no_uniprot': 0, 'no_pdb': 0, 'no_sequence': 0}\n",
      "\n",
      "processed jinyuan_sun_test:\n",
      "errors={'no_sequence_in_data': 0, 'not_in_local': 0, 'wrong_position': 0, 'no_uniprot': 0, 'no_pdb': 0, 'no_sequence': 0}\n",
      "\n",
      "processed datasetDDG_train:\n",
      "errors={'no_sequence_in_data': 0, 'not_in_local': 0, 'wrong_position': 1527, 'no_uniprot': 0, 'no_pdb': 0, 'no_sequence': 0}\n",
      "\n",
      "processed datasetDDG_test:\n",
      "errors={'no_sequence_in_data': 0, 'not_in_local': 0, 'wrong_position': 73, 'no_uniprot': 0, 'no_pdb': 0, 'no_sequence': 0}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if FRESH_START:\n",
    "    main_df = pd.DataFrame()\n",
    "    main_df = add_missing_column(main_df, COLUMNS)\n",
    "else:\n",
    "    main_df = pd.read_csv(DATASET_OUTPUT_PATH_RAW)\n",
    "\n",
    "for dataset_source in dataset_config[\"dataset_to_process\"]:\n",
    "    errors = {\n",
    "        \"no_sequence_in_data\": 0,\n",
    "        \"not_in_local\": 0,\n",
    "        \"wrong_position\": 0,\n",
    "        \"no_uniprot\": 0,\n",
    "        \"no_pdb\": 0,\n",
    "        \"no_sequence\": 0,\n",
    "    }\n",
    "\n",
    "    individual_config = dataset_config[dataset_source]\n",
    "    # load csv\n",
    "    if dataset_source == \"thermomutdb\":\n",
    "        df = pd.read_json(individual_config[\"data_path\"])\n",
    "        df = df[df.mut_count.eq(0)]\n",
    "        df[df.uniprot.eq('-')] = np.nan\n",
    "        print(len(df))\n",
    "    else:\n",
    "        df = pd.read_csv(individual_config[\"data_path\"])\n",
    "    # rename columns\n",
    "    df.rename(columns=individual_config[\"renaming_dict\"],\n",
    "              inplace=True)\n",
    "    # add missing columns\n",
    "    df = add_missing_column(df, COLUMNS)\n",
    "    # split mutation code if needed\n",
    "    if individual_config[\"need_mutation_code_split\"]:\n",
    "        df = df.apply(apply_split_mutation_code, axis=1)\n",
    "    # remove nan mutation_code\n",
    "    df = df[~df[\"mutation_position\"].isna()]\n",
    "    # keep only COLUMNS\n",
    "    df = df[COLUMNS]\n",
    "    # drop duplicates\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    # add dataset_source\n",
    "    df[\"dataset_source\"] = dataset_source\n",
    "    # index start at 0\n",
    "    df[\"mutation_position\"] = df[\"mutation_position\"].apply(lambda x: x-1)\n",
    "    # apply target corrections\n",
    "    df[\"ddG\"] = df[\"ddG\"].apply(\n",
    "        lambda x: x*individual_config[\"corrections\"][\"ddG\"])\n",
    "    df[\"dTm\"] = df[\"dTm\"].apply(\n",
    "        lambda x: x*individual_config[\"corrections\"][\"dTm\"])\n",
    "    # better to initialize infos_found at 0 than nan\n",
    "    df[\"infos_found\"] = 0\n",
    "    \n",
    "    # check number of rows without uniprot\n",
    "    # check validity of uniprot, and add the infos for those\n",
    "    df = df.apply(lambda row: apply_valid_uniprot(\n",
    "        row, local_uniprot_infos, dataset_config, errors), axis=1)\n",
    "    \n",
    "    \n",
    "    print(f\"processed {dataset_source}:\")\n",
    "    print(f\"{errors=}\\n\")\n",
    "\n",
    "    main_df = pd.concat([main_df, df], ignore_index=True)\n",
    "    main_df.drop_duplicates(SUBSET_DUPLICATES, inplace=True)\n",
    "\n",
    "# save\n",
    "write_json(LOCAL_UNIPROT_INFOS_PATH, local_uniprot_infos)\n",
    "main_df.to_csv(DATASET_OUTPUT_PATH_RAW, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasetDDG_test    276\n",
      "Name: dataset_source, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# total number of elements before any filtering:\n",
    "# fireprotdb          34448\n",
    "# thermomutdb         13633\n",
    "# prothermdb           8740\n",
    "# O2567_new            2568\n",
    "# datasetDDG_train     5444\n",
    "# datasetDDG_test       276\n",
    "# jinyuan_sun_train    4048\n",
    "# jinyuan_sun_test      168\n",
    "print(df.dataset_source.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### update mapping and try to add infos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not UPDATE_MAPPING:\n",
    "    # don't go beyond here with Run All\n",
    "    assert False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added 0 entries to pdb_uniprot_mapping\n"
     ]
    }
   ],
   "source": [
    "# update pdb to uniprot mapping\n",
    "update_pdb_uniprot_mapping(LOCAL_UNIPROT_INFOS_PATH,\n",
    "                           PDB_UNIPROT_MAPPING_PATH,\n",
    "                           LINKED_UNIPROT_MAPPING_PATH)\n",
    "\n",
    "pdb_uniprot_mapping = open_json(PDB_UNIPROT_MAPPING_PATH)\n",
    "linked_uniprot_mapping = open_json(LINKED_UNIPROT_MAPPING_PATH)\n",
    "pdb_without_uniprot = open_json(PDB_NO_UNIPROT_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added 2362.0 new infos thanks to uniprot_from_pdb\n"
     ]
    }
   ],
   "source": [
    "# add infos based on pdb not uniprot\n",
    "df = pd.read_csv(DATASET_OUTPUT_PATH_RAW)\n",
    "\n",
    "with_infos = df.infos_found.sum()\n",
    "df = df.apply(lambda row: apply_infos_from_pdb(row, local_uniprot_infos, pdb_uniprot_mapping,\n",
    "                                               linked_uniprot_mapping, dataset_config,\n",
    "                                               pdb_without_uniprot, errors),\n",
    "              axis=1)\n",
    "print(\n",
    "    f\"added {df.infos_found.sum()-with_infos} new infos thanks to uniprot_from_pdb\")\n",
    "df.to_csv(DATASET_OUTPUT_PATH_RAW, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added 0 entries to sequence_uniprot_mapping\n"
     ]
    }
   ],
   "source": [
    "# update sequence to uniprot mapping\n",
    "update_sequence_uniprot_mapping(LOCAL_UNIPROT_INFOS_PATH,\n",
    "                                SEQUENCE_UNIPROT_MAPPING_PATH,\n",
    "                                LINKED_UNIPROT_MAPPING_PATH)\n",
    "\n",
    "sequence_uniprot_mapping = open_json(SEQUENCE_UNIPROT_MAPPING_PATH)\n",
    "sequence_without_uniprot = open_json(SEQUENCE_NO_UNIPROT_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added 0.0 new infos thanks to uniprot_from_sequence\n"
     ]
    }
   ],
   "source": [
    "# add infos based on sequence not pdb or uniprot\n",
    "\n",
    "df = pd.read_csv(DATASET_OUTPUT_PATH_RAW)\n",
    "\n",
    "with_infos = df.infos_found.sum()\n",
    "df = df.apply(lambda row: apply_infos_from_sequence(row, local_uniprot_infos, sequence_uniprot_mapping,\n",
    "                                                    linked_uniprot_mapping, dataset_config,\n",
    "                                                    sequence_without_uniprot, errors),\n",
    "              axis=1)\n",
    "print(\n",
    "    f\"added {df.infos_found.sum()-with_infos} new infos thanks to uniprot_from_sequence\")\n",
    "\n",
    "df.to_csv(DATASET_OUTPUT_PATH_RAW, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure mapping and other data is saved\n",
    "write_json(LOCAL_UNIPROT_INFOS_PATH, local_uniprot_infos)\n",
    "write_json(PDB_NO_UNIPROT_PATH, pdb_without_uniprot)\n",
    "write_json(SEQUENCE_NO_UNIPROT_PATH, sequence_without_uniprot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20922\n"
     ]
    }
   ],
   "source": [
    "main_df = pd.read_csv(DATASET_OUTPUT_PATH_RAW)\n",
    "# remove pdbs\n",
    "main_df = main_df[COLUMNS[1:]]\n",
    "# remove record without uniprot infos\n",
    "main_df = main_df[~main_df.infos_found.eq(\"0.0\")]\n",
    "print(len(main_df))\n",
    "main_df.to_csv(DATASET_OUTPUT_PATH_ONLY_INFOS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick check of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"I\"\n",
    "s=\"MMSFVSLLLVGILFHATQAEQLTKCEVFQKLKDLKDYGGVSLPEWVCTAFHTSGYDTQAIVQNNDSTEYGLFQINNKIWCKDDQNPHSRNICNISCDKFLDDDLTDDIVCAKKILDKVGINYWLAHKALCSEKLDQWLCEKL\"\n",
    "s[107]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4147"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df.pH.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "548"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(main_df.uniprot.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14882\n",
      "6066\n",
      "4047\n"
     ]
    }
   ],
   "source": [
    "print(len(main_df)-main_df.ddG.isna().sum())\n",
    "print(len(main_df)-main_df.dTm.isna().sum())\n",
    "print(len(main_df)-main_df.Tm.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fireprotdb           6724\n",
      "thermomutdb          5655\n",
      "jinyuan_sun_train    3473\n",
      "O2567_new            2522\n",
      "prothermdb           1491\n",
      "datasetDDG_train      864\n",
      "jinyuan_sun_test      127\n",
      "datasetDDG_test        66\n",
      "Name: dataset_source, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# total number of elements:\n",
    "# fireprotdb          34448\n",
    "# thermomutdb         13633\n",
    "# prothermdb           8740\n",
    "# O2567_new            2568\n",
    "# datasetDDG_train     5444\n",
    "# datasetDDG_test       276\n",
    "# jinyuan_sun_train    4048\n",
    "# jinyuan_sun_test      168\n",
    "print(main_df.dataset_source.value_counts())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('novozymes-prediction-Gl9CRTFV')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "27b13dc4add9efa918e6bb920c50afa2240557655d90455391ab57f21c65447b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
