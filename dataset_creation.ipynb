{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS = [\"PDB_wild\", \"mutated_chain\", \"mutation_code\", \"mutation_sequence_code\", \"pH\", \"Texp\", \"Tm\", \"ddG\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Ssym+ and remove predictions and index columns\n",
    "columns_experimental = [\"Protein\",\"Mut_pdb\",\"DDG_dir\",\"DDG_inv\",\"DDG\",\"Ph\",\"T\",\"Mut_Seq\",\"Protein_inv\",\"Mut_pdb_inv\",\"Mut_Seq_inv\"]\n",
    "ssym_dir_df = pd.read_csv(\"./data/Ssym+/Ssym+_experimental.csv\")[columns_experimental]\n",
    "\n",
    "# then for each line we create a new line for the reverse mutation\n",
    "# add Texp and Tm columns\n",
    "ssym_dir_df[\"Texp\"] = np.nan\n",
    "ssym_dir_df[\"Tm\"] = np.nan\n",
    "ssym_dir_df[\"PDB_wild\"] = np.nan\n",
    "ssym_dir_df[\"mutated_chain\"] = np.nan\n",
    "ssym_dir_df = ssym_dir_df.rename(columns={\"Ph\": \"pH\", \"Mut_pdb\": \"mutation_code\", \"Mut_Seq\": \"mutation_sequence_code\", \"DDG\": \"ddG\"})\n",
    "\n",
    "\n",
    "\n",
    "def process_temperature(row):\n",
    "    if row[\"T\"] == 25:\n",
    "        row[\"Texp\"] = row[\"T\"]+273.15\n",
    "    else:\n",
    "        row[\"Tm\"] = row[\"T\"]+273.15\n",
    "    return row\n",
    "\n",
    "def process_prot_name(row):\n",
    "    name = row[\"Protein\"]\n",
    "    row[\"PDB_wild\"]=name[:-1].upper()\n",
    "    row[\"mutated_chain\"]=name[-1]\n",
    "    return row\n",
    "\n",
    "ssym_dir_df = ssym_dir_df.apply(process_temperature, axis=1)\n",
    "ssym_dir_df = ssym_dir_df.apply(process_prot_name, axis=1)\n",
    "ssym_dir_df = ssym_dir_df.drop(columns=[\"T\", \"Protein\"])\n",
    "\n",
    "def create_reverse_row(row):\n",
    "    reverse_row = []\n",
    "    for name in COLUMNS:\n",
    "        k = name+\"_inv\" if (name+\"_inv\" in row) else name\n",
    "        reverse_row.append(row[k])\n",
    "    return pd.Series(reverse_row)\n",
    "\n",
    "\n",
    "ssym_reverse_df = ssym_dir_df.apply(create_reverse_row, axis=1)\n",
    "ssym_reverse_df.columns = COLUMNS\n",
    "ssym_dir_df = ssym_dir_df[COLUMNS]\n",
    "ssym_df = pd.concat([ssym_dir_df, ssym_reverse_df], ignore_index=True)\n",
    "\n",
    "ssym_df.to_csv(\"./data/main_dataset/ssym.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "thermomut_df = pd.read_json(\"./data/ThermoMutDB/thermomutdb.json\")\n",
    "\n",
    "columns_to_rm = [\"year\", \"reference\", \"PMID\"]\n",
    "thermomut_df.drop(columns=columns_to_rm, axis=1, inplace=True)\n",
    "\n",
    "thermomut_df = thermomut_df.rename(columns={\"temperature\": \"Texp\", \"ph\": \"pH\", \"dtm\": \"dTm\", \"ddg\": \"ddG\"})\n",
    "thermomut_cols = thermomut_df.columns.to_list()\n",
    "\n",
    "for name in COLUMNS:\n",
    "    if name not in thermomut_cols:\n",
    "        thermomut_df[name] = np.nan\n",
    "\n",
    "thermomut_df = thermomut_df[COLUMNS+(list(set(thermomut_cols)-set(COLUMNS)))]\n",
    "thermomut_df.to_csv(\"./data/main_dataset/thermomutdb.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "o2567_df = pd.read_csv(\"./data/O2567_new/O2567_new.csv\")\n",
    "o2567_df = o2567_df.rename(columns={\"PDB code\": \"PDB_wild\", \"Chain\": \"mutated_chain\", \"dtm\": \"dTm\", \n",
    "                                    \"Experimental ddG\": \"ddG\", \"Temperature\": \"Texp\", \"Method\": \"method\",\n",
    "                                    \"RSA\": \"rsa\"\n",
    "                                    })\n",
    "\n",
    "for name in COLUMNS:\n",
    "    if name not in o2567_df.columns.to_list():\n",
    "        o2567_df[name] = np.nan\n",
    "\n",
    "\n",
    "def process_o2567(row):\n",
    "    # convert to mutation code directly\n",
    "    row[\"mutation_code\"] = row[\"Wild\"]+str(row[\"Residue number\"])+row[\"Mutated\"]\n",
    "    # convert Temp to K (same as ThermoMutDB)\n",
    "    t = row[\"Texp\"]\n",
    "    if type(t)==type(\"\") and \" K\" in t:\n",
    "        row[\"Texp\"] = float(t[:-2])\n",
    "    else:\n",
    "        row[\"Texp\"] = float(t) + 273.15\n",
    "    return row\n",
    "\n",
    "\n",
    "\n",
    "o2567_df = o2567_df.apply(process_o2567, axis=1)\n",
    "o2567_df = o2567_df[COLUMNS]\n",
    "o2567_df.to_csv(\"./data/main_dataset/o2567.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"pdb,wildtype,pdb_resseq,seq_index,mutation,wt_seq,mut_seq,ddG\"\n",
    "v2_test_df = pd.read_csv(\"./data/jinyuan_sun/v2/test.csv\")\n",
    "\"pdb,wildtype,pdb_resseq,seq_index,mutation,wt_seq,mut_seq,ddG,group\"\n",
    "v2_train_df = pd.read_csv(\"./data/jinyuan_sun/v2/train.csv\")\n",
    "\n",
    "v2_train_df.drop(columns=[\"group\"], axis=1, inplace=True)\n",
    "\n",
    "jinyuan_sun_df = pd.concat([v2_test_df, v2_train_df], ignore_index=True)\n",
    "jinyuan_sun_df.rename(columns={\"pdb\": \"PDB_wild\", \"wt_seq\": \"wildtype_seq\", \n",
    "                                \"mut_seq\": \"mutated_seq\"}, inplace=True)\n",
    "\n",
    "def process_jinyuan_sun(row):\n",
    "    # convert to mutation code directly\n",
    "    row[\"mutation_code\"] = row[\"wildtype\"]+str(row[\"pdb_resseq\"])+row[\"mutation\"]\n",
    "    row[\"mutation_sequence_code\"] = row[\"wildtype\"]+str(row[\"seq_index\"])+row[\"mutation\"]\n",
    "    return row\n",
    "\n",
    "jinyuan_sun_df = jinyuan_sun_df.apply(process_jinyuan_sun, axis=1)\n",
    "jinyuan_sun_df.drop(columns=[\"wildtype\", \"pdb_resseq\", \"seq_index\", \"mutation\"], axis=1, inplace=True)\n",
    "\n",
    "for name in COLUMNS:\n",
    "    if name not in jinyuan_sun_df.columns.to_list():\n",
    "        jinyuan_sun_df[name] = np.nan\n",
    "    \n",
    "jinyuan_sun_df = jinyuan_sun_df[COLUMNS]\n",
    "jinyuan_sun_df.to_csv(\"./data/main_dataset/jinyuan_sun.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv obtained by searching all values with \"has_ddg\"\n",
    "fire_df = pd.read_csv(\"./data/FireProtDB/fireprotdb_has_ddg_is_curated.csv\")\n",
    "\n",
    "# Keep only curated data\n",
    "fire_df = fire_df[fire_df[\"is_curated\"]]\n",
    "\n",
    "# Drop duplicate rows\n",
    "# THIS REMOVE 14k entries !!!!\n",
    "duplicate_subset = [\"pdb_id\", \"dTm\", \"ddG\", \"chain\", \"wild_type\", \"position\", \"mutation\", \"sequence\"]\n",
    "fire_df = fire_df.drop_duplicates(duplicate_subset)\n",
    "\n",
    "# Remove weird duplicate pdb ids in the pdb_id column (keep '|' for now)\n",
    "fire_df[\"pdb_id\"] = fire_df[\"pdb_id\"].apply(lambda x: x if \"|\" not in x else \"|\".join(list(set(x.split(\"|\")))))\n",
    "\n",
    "# Remove columns without useful informations\n",
    "fire_df = fire_df.drop(columns=['is_curated', 'is_essential', 'is_back_to_consensus', 'method_details', \n",
    "'technique_details', 'notes', 'publication_doi', 'publication_pubmed'])\n",
    "\n",
    "# fire_df.columns.to_list()\n",
    "fire_df.rename(columns={\"pdb_id\": \"PDB_wild\", \"chain\": \"mutated_chain\", \"tm\": \"Tm\"}, inplace=True)\n",
    "\n",
    "for name in COLUMNS:\n",
    "    if name not in fire_df.columns.to_list():\n",
    "        fire_df[name] = np.nan\n",
    "\n",
    "def process_fire(row):\n",
    "    # convert to mutation code directly\n",
    "    row[\"mutation_code\"] = row[\"wild_type\"]+str(row[\"position\"])+row[\"mutation\"]\n",
    "    return row\n",
    "\n",
    "fire_df = fire_df.apply(process_fire, axis=1)\n",
    "fire_df.drop(columns=[\"wild_type\", \"position\", \"mutation\"], axis=1, inplace=True)\n",
    "\n",
    "fire_df = fire_df[COLUMNS+(list(set(fire_df.columns.to_list())-set(COLUMNS)))]\n",
    "fire_df.to_csv(\"./data/main_dataset/firedb.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('novozymes-prediction-Gl9CRTFV')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "27b13dc4add9efa918e6bb920c50afa2240557655d90455391ab57f21c65447b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
