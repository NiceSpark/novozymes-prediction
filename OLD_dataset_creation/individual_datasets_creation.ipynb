{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual Datasets Creation\n",
    "see [./data/sources.csv](./data/sources.csv) for the different sources where we were able to download each datasets\n",
    "Simply put there exist a few dataset containing information about the impact of mutations on protein stability.\n",
    "The main 3 big dataset that exist as of Oct. 2022 are:\n",
    "- FireProtDB\n",
    "- ThermoMutDB\n",
    "- ProThermDB\n",
    "\n",
    "Which all incorporates data from the same old DB (ProTherm) and additionnal data added by each DB devs.\n",
    "There exists also other datasets, that were cited in papers from the litterature.\n",
    "We can expect a lot of redundancies between each datasets.\n",
    "\n",
    "\n",
    "The goal of this Notebook is to create coherent datasets from each DB, in order to then compare them and put them all together.\n",
    "The merging itself is done in another Notebook: [datasets_merging](./datasets_merging.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pypdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS = [\"PDB_wild\", \"uniprot\", \"mutated_chain\", \"mutation_code\", \"pH\", \"Texp\", \"Tm\", \"ddG\", \"dTm\"]\n",
    "# \"mutation_sequence_code\"\n",
    "# turn to False if you want to save all available info in the db\n",
    "SAVE_ONLY_COLUMNS = True\n",
    "\n",
    "def add_missing_column(df):\n",
    "    for name in COLUMNS:\n",
    "        if name not in df.columns.to_list():\n",
    "            df[name] = np.nan\n",
    "    \n",
    "    return df\n",
    "\n",
    "def save_df(df, name):\n",
    "    if SAVE_ONLY_COLUMNS:\n",
    "        df = df[COLUMNS]\n",
    "    df.to_csv(f\"./data/main_dataset/{name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_to_pdb(seq):\n",
    "    # get pdb id from protein sequence using the pypdb package to query the RCSB Protein Data Bank API\n",
    "    q = pypdb.Query(seq, \n",
    "        query_type=\"sequence\", \n",
    "        return_type=\"polymer_entity\")\n",
    "    \n",
    "    for result in q.search()[\"result_set\"]:\n",
    "        [result_id, chain] = result[\"identifier\"].split('_')\n",
    "        if result[\"score\"] == 1.0 and chain==\"1\":\n",
    "            return result_id\n",
    "\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Ssym+ #####\n",
    "\n",
    "# load Ssym+ and remove predictions and index columns\n",
    "columns_experimental = [\"Protein\",\"Mut_pdb\",\"DDG_dir\",\"DDG_inv\",\"DDG\",\"Ph\",\"T\",\"Mut_Seq\",\"Protein_inv\",\"Mut_pdb_inv\",\"Mut_Seq_inv\"]\n",
    "ssym_dir_df = pd.read_csv(\"./data/Ssym+/Ssym+_experimental.csv\")[columns_experimental]\n",
    "\n",
    "ssym_dir_df.rename(columns={\"Ph\": \"pH\", \"Mut_pdb\": \"mutation_code\", \n",
    "                            \"Mut_Seq\": \"mutation_sequence_code\", \"DDG_dir\": \"ddG\", \"DDG_inv\": \"ddG_inv\"}\n",
    "                            , inplace=True)\n",
    "ssym_dir_df = add_missing_column(ssym_dir_df)\n",
    "\n",
    "\n",
    "def process_temperature(row):\n",
    "    if row[\"T\"] == 25:\n",
    "        row[\"Texp\"] = row[\"T\"]+273.15\n",
    "    else:\n",
    "        row[\"Tm\"] = row[\"T\"]+273.15\n",
    "    return row\n",
    "\n",
    "def process_prot_name(row):\n",
    "    name = row[\"Protein\"]\n",
    "    row[\"PDB_wild\"]=name[:-1].upper()\n",
    "    row[\"mutated_chain\"]=name[-1]\n",
    "    return row\n",
    "\n",
    "ssym_dir_df = ssym_dir_df.apply(process_temperature, axis=1)\n",
    "ssym_dir_df = ssym_dir_df.apply(process_prot_name, axis=1)\n",
    "ssym_dir_df = ssym_dir_df.drop(columns=[\"T\", \"Protein\"])\n",
    "\n",
    "def create_reverse_row(row):\n",
    "    reverse_row = []\n",
    "    row[\"PDB_wild\"] = row[\"Protein_inv\"][:-1].upper()\n",
    "    row[\"mutated_chain\"] = row[\"Protein_inv\"][-1]\n",
    "\n",
    "    for name in COLUMNS:\n",
    "        k = name+\"_inv\" if (name+\"_inv\" in row) else name\n",
    "        reverse_row.append(row[k])\n",
    "\n",
    "    return pd.Series(reverse_row)\n",
    "\n",
    "\n",
    "# then for each line we create a new line for the reverse mutation\n",
    "ssym_reverse_df = ssym_dir_df.apply(create_reverse_row, axis=1)\n",
    "ssym_reverse_df.columns = COLUMNS\n",
    "ssym_dir_df = ssym_dir_df[COLUMNS]\n",
    "\n",
    "ssym_df = pd.concat([ssym_dir_df, ssym_reverse_df], ignore_index=True)\n",
    "\n",
    "save_df(ssym_df, \"ssym\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ThermoMutDB #####\n",
    "\n",
    "thermomut_df = pd.read_json(\"./data/ThermoMutDB/thermomutdb.json\")\n",
    "\n",
    "columns_to_rm = [\"year\", \"reference\", \"PMID\"]\n",
    "thermomut_df.drop(columns=columns_to_rm, axis=1, inplace=True)\n",
    "\n",
    "thermomut_df = thermomut_df.rename(columns={\"temperature\": \"Texp\", \"ph\": \"pH\", \"dtm\": \"dTm\", \"ddg\": \"ddG\"})\n",
    "\n",
    "def process_code(row):\n",
    "    # \"R15H,E20S\" => R15H E20S\n",
    "    code = row[\"mutation_code\"]\n",
    "    if ',' in code:\n",
    "        row[\"mutation_code\"] = ' '.join([s.replace('\"', '') for s in code.split(',')])\n",
    "    return row\n",
    "\n",
    "thermomut_df = add_missing_column(thermomut_df)\n",
    "thermomut_df = thermomut_df[COLUMNS+(list(set(thermomut_df.columns.to_list())-set(COLUMNS)))]\n",
    "thermomut_df = thermomut_df.apply(process_code, axis=1)\n",
    "save_df(thermomut_df, \"thermomut\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### O2567 #####\n",
    "\n",
    "o2567_df = pd.read_csv(\"./data/O2567_new/O2567_new.csv\")\n",
    "o2567_df = o2567_df.rename(columns={\"PDB code\": \"PDB_wild\", \"Chain\": \"mutated_chain\", \"dtm\": \"dTm\", \n",
    "                                    \"Experimental ddG\": \"ddG\", \"Temperature\": \"Texp\", \"Method\": \"method\",\n",
    "                                    \"RSA\": \"rsa\"\n",
    "                                    })\n",
    "\n",
    "o2567_df = add_missing_column(o2567_df)\n",
    "\n",
    "def process_o2567(row):\n",
    "    # convert to mutation code directly\n",
    "    row[\"mutation_code\"] = row[\"Wild\"]+str(row[\"Residue number\"])+row[\"Mutated\"]\n",
    "    # convert Temp to K (same as ThermoMutDB)\n",
    "    t = row[\"Texp\"]\n",
    "    if type(t)==type(\"\") and \" K\" in t:\n",
    "        row[\"Texp\"] = float(t[:-2])\n",
    "    else:\n",
    "        row[\"Texp\"] = float(t) + 273.15\n",
    "    return row\n",
    "\n",
    "\n",
    "\n",
    "o2567_df = o2567_df.apply(process_o2567, axis=1)\n",
    "o2567_df = o2567_df[COLUMNS]\n",
    "save_df(o2567_df, \"o2567\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Jynyuan Sun's dataset (Phd. student in bio) #####\n",
    "\n",
    "\"pdb,wildtype,pdb_resseq,seq_index,mutation,wt_seq,mut_seq,ddG\"\n",
    "v2_test_df = pd.read_csv(\"./data/jinyuan_sun/v2/test.csv\")\n",
    "\"pdb,wildtype,pdb_resseq,seq_index,mutation,wt_seq,mut_seq,ddG,group\"\n",
    "v2_train_df = pd.read_csv(\"./data/jinyuan_sun/v2/train.csv\")\n",
    "\n",
    "v2_train_df.drop(columns=[\"group\"], axis=1, inplace=True)\n",
    "\n",
    "jinyuan_sun_df = pd.concat([v2_test_df, v2_train_df], ignore_index=True)\n",
    "jinyuan_sun_df.rename(columns={\"pdb\": \"PDB_wild\", \"wt_seq\": \"wildtype_seq\", \n",
    "                                \"mut_seq\": \"mutated_seq\"}, inplace=True)\n",
    "\n",
    "def process_jinyuan_sun(row):\n",
    "    # convert to mutation code directly\n",
    "    row[\"mutation_code\"] = row[\"wildtype\"]+str(row[\"pdb_resseq\"])+row[\"mutation\"]\n",
    "    row[\"mutation_sequence_code\"] = row[\"wildtype\"]+str(row[\"seq_index\"])+row[\"mutation\"]\n",
    "    return row\n",
    "\n",
    "jinyuan_sun_df = jinyuan_sun_df.apply(process_jinyuan_sun, axis=1)\n",
    "jinyuan_sun_df.drop(columns=[\"wildtype\", \"pdb_resseq\", \"seq_index\", \"mutation\"], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "jinyuan_sun_df = add_missing_column(jinyuan_sun_df)\n",
    "    \n",
    "save_df(jinyuan_sun_df, \"jinyuan_sun\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### FireProtDB #####\n",
    "\n",
    "# csv obtained by searching all values with \"has_ddg\"\n",
    "fire_df = pd.read_csv(\"./data/FireProtDB/fireprotdb_has_ddg_or_dtm_is_curated.csv\")\n",
    "\n",
    "# Keep only curated data\n",
    "fire_df = fire_df[fire_df[\"is_curated\"]]\n",
    "\n",
    "# Drop duplicate rows\n",
    "# THIS REMOVE 14k+ entries !!!!\n",
    "duplicate_subset = [\"pdb_id\", \"dTm\", \"ddG\", \"chain\", \"wild_type\", \"position\", \"mutation\", \"sequence\"]\n",
    "fire_df = fire_df.drop_duplicates(duplicate_subset)\n",
    "\n",
    "# Drop rows with no valid pdb files ~10-15\n",
    "fire_df = fire_df[~pd.isna(fire_df.pdb_id)]\n",
    "# Remove weird duplicate pdb ids in the pdb_id column (keep '|' for now)\n",
    "fire_df[\"pdb_id\"] = fire_df[\"pdb_id\"].apply(lambda x: x if \"|\" not in x else \"|\".join(list(set(x.split(\"|\")))))\n",
    "\n",
    "# Remove columns without useful informations\n",
    "fire_df = fire_df.drop(columns=['is_curated', 'is_essential', 'is_back_to_consensus', 'method_details', \n",
    "'technique_details', 'notes', 'publication_doi', 'publication_pubmed'])\n",
    "\n",
    "# fire_df.columns.to_list()\n",
    "fire_df.rename(columns={\"pdb_id\": \"PDB_wild\", \"chain\": \"mutated_chain\", \"tm\": \"Tm\", \"uniprot_id\": \"uniprot\"}, inplace=True)\n",
    "\n",
    "fire_df = add_missing_column(fire_df)\n",
    "\n",
    "# count_wrong_seq_to_pdb = 0\n",
    "# no_seq_to_pdb = 0\n",
    "# wrong_seq_to_pdb_ids = []\n",
    "# count = 0\n",
    "\n",
    "def process_fire(row):\n",
    "    row[\"mutation_code\"] = row[\"wild_type\"]+str(row[\"position\"])+row[\"mutation\"]\n",
    "    \n",
    "    # global count_wrong_seq_to_pdb\n",
    "    # global wrong_seq_to_pdb_ids\n",
    "    # global no_seq_to_pdb\n",
    "    # global count\n",
    "\n",
    "    # if count < 100:\n",
    "    #     count += 1\n",
    "    #     # convert to mutation code directly\n",
    "    #     computed_pdb = seq_to_pdb(row[\"sequence\"])\n",
    "    #     if computed_pdb == \"\":\n",
    "    #         no_seq_to_pdb += 1\n",
    "    #     elif (computed_pdb not in row[\"PDB_wild\"]):\n",
    "    #         count_wrong_seq_to_pdb += 1\n",
    "    #         wrong_seq_to_pdb_ids.append(row[\"experiment_id\"])\n",
    "    return row\n",
    "\n",
    "fire_df = fire_df.apply(process_fire, axis=1)\n",
    "\n",
    "# print(f\"{count_wrong_seq_to_pdb=}\")\n",
    "# print(f\"{no_seq_to_pdb=}\")\n",
    "# from utils.file_utils import write_json\n",
    "# write_json(\"wrong_seq_to_pdb_ids.json\", wrong_seq_to_pdb_ids)\n",
    "\n",
    "fire_df.drop(columns=[\"wild_type\", \"position\", \"mutation\"], axis=1, inplace=True)\n",
    "\n",
    "fire_df = fire_df[COLUMNS+(list(set(fire_df.columns.to_list())-set(COLUMNS)))]\n",
    "save_df(fire_df, \"fireprotdb_ddg_dtm_curated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Kaggle (competition dataset) #####\n",
    "\n",
    "kaggle_df = pd.read_csv(\"./data/Kaggle/updated_train.csv\")\n",
    "kaggle_df.rename(columns={\"tm\": \"Tm\", \"protein_sequence\": \"mutated_seq\"}, inplace=True)\n",
    "\n",
    "kaggle_df = add_missing_column(kaggle_df)\n",
    "kaggle_df = kaggle_df[COLUMNS+(list(set(kaggle_df.columns.to_list())-set(COLUMNS)))]\n",
    "\n",
    "save_df(kaggle_df, \"kaggle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### DeepDDG dataset #####\n",
    "train_df = pd.read_csv(\"./data/DeepDDG_train_dataset/datasetDDG_train.csv\")\n",
    "test_df = pd.read_csv(\"./data/DeepDDG_train_dataset/datasetDDG_test.csv\")\n",
    "\n",
    "train_df.drop(columns=\"Fold ID in 10-fold cross validation\", axis=1, inplace= True)\n",
    "deepddg_df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "deepddg_df.rename(columns={\"Mutation\": \"mutation_code\", \"T\": \"Texp\", \"ΔΔG (kcal/mol) positive is stable\": \"ddG\", \n",
    "                            \"PDB ID with modifications to be made\": \"PDB_wild\", \"Uniprot ID\": \"uniprot\",\n",
    "                            \"Source\": \"source\", \"Protein name\": \"protein\", \"PubMed ID\": \"PMID\"}, \n",
    "                            inplace= True)\n",
    "\n",
    "deepddg_df = add_missing_column(deepddg_df)\n",
    "\n",
    "# remove '_' from mutation code\n",
    "def process_deepddg(row):\n",
    "    row[\"mutation_code\"] = row[\"mutation_code\"].replace(\"_\", \"\")\n",
    "    row[\"Texp\"] += 273.15\n",
    "    return row\n",
    "\n",
    "deepddg_df = deepddg_df.apply(process_deepddg, axis=1)\n",
    "\n",
    "deepddg_df = deepddg_df[COLUMNS+(list(set(deepddg_df.columns.to_list())-set(COLUMNS)))]\n",
    "save_df(deepddg_df, \"deepddg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ProThermDB #####\n",
    "all_ddg_df = pd.read_csv(\"./data/ProThermDB/prothermdb_all_ddg.tsv\", sep=\"\\t\")\n",
    "all_dtm_df = pd.read_csv(\"./data/ProThermDB/prothermdb_all_dTm.tsv\", sep=\"\\t\")\n",
    "\n",
    "prothermdb_df = pd.concat([all_ddg_df, all_dtm_df], ignore_index=True)\n",
    "\n",
    "# removes duplicate: ~400 rows\n",
    "prothermdb_df = prothermdb_df.drop_duplicates()\n",
    "\n",
    "# columns we let \"as is\" \n",
    "# ['LENGTH', '∆G_H2O_(kcal/mol)', '∆∆G_H2O_(kcal/mol)', '∆H_(kcal/mol)', '∆HvH_(kcal/mol)', 'm_(kcal/mol/M)', 'Cm_(M)', '∆Cp_(kcal/mol)', 'STATE', 'REVERSIBILITY']\n",
    "\n",
    "prothermdb_df.rename(columns={\"PROTEIN\": \"protein\", \"UniProt_ID\": \"uniprot\", \"PubMed_ID\": \"PMID\",\n",
    "                                \"SOURCE\": \"source\", 'T_(C)': \"Texp\", 'MEASURE': \"measure\", 'METHOD': \"method\",\n",
    "                                '∆G_(kcal/mol)': \"dG\", '∆∆G_(kcal/mol)': \"ddG\", 'Tm_(C)':\"Tm\", '∆Tm_(C)': \"dTm\"}, \n",
    "                    inplace= True)\n",
    "\n",
    "prothermdb_df = add_missing_column(prothermdb_df)\n",
    "\n",
    "def process_prothermdb(row):\n",
    "    for k in row.keys():\n",
    "        if row[k]=='-':\n",
    "            row[k]=\"\"\n",
    "    \n",
    "    # coherent PDB_WILD: all caps\n",
    "    row[\"PDB_wild\"] = row[\"PDB_wild\"].upper()\n",
    "\n",
    "    # 1st: convert T to float (sometimes: 23(1.2) or >96)\n",
    "    if '>' in row[\"Tm\"]:\n",
    "        row[\"Tm\"] = row[\"Tm\"].split(\">\")[1]\n",
    "\n",
    "    texp = float(row[\"Texp\"].split('(')[0]) if row[\"Texp\"] else np.nan\n",
    "    tm = float(row[\"Tm\"].split('(')[0]) if row[\"Tm\"] else np.nan\n",
    "    # 2nd: convert temperatures from C to K\n",
    "    row[\"Texp\"] = texp + 273.15 if texp else np.nan\n",
    "    row[\"Tm\"] = tm + 273.15  if tm else np.nan\n",
    "    \n",
    "    # make sure that dTm, ddG and Tm are all floats:\n",
    "    row[\"ddG\"] = float(str(row[\"ddG\"]).split('(')[0]) if row[\"ddG\"] else np.nan\n",
    "    row[\"dTm\"] = float(str(row[\"dTm\"]).split('(')[0]) if row[\"dTm\"] else np.nan\n",
    "    row[\"Tm\"] = float(str(row[\"Tm\"]).split('(')[0]) if row[\"Tm\"] else np.nan\n",
    "\n",
    "\n",
    "    # handling the difference in mutation code, including multiple mutations\n",
    "    row[\"mutated_chain\"] = \"\"\n",
    "    row[\"mutation_code\"] = \"\"\n",
    "\n",
    "    if row[\"PDB_Chain_Mutation\"]:\n",
    "        pdb_split = [s.split(\":\") for s in row[\"PDB_Chain_Mutation\"].split(' ')]\n",
    "        for s in pdb_split:\n",
    "            if len(s)!=2:\n",
    "                continue\n",
    "            [pdb_wild, mut] = s\n",
    "            # normally we have 1csp_A => A\n",
    "            if '_' in pdb_wild:\n",
    "                row[\"mutated_chain\"] += pdb_wild.split('_')[-1]\n",
    "            \n",
    "            # sometimes we have A_M1R => A & M1R\n",
    "            if '_' in mut:\n",
    "                row[\"mutated_chain\"] += mut.split('_')[0]\n",
    "                row[\"mutation_code\"] += mut.split('_')[1]+\" \"\n",
    "            else:\n",
    "                row[\"mutation_code\"] += mut+\" \"\n",
    "\n",
    "    # M1R E3K K65I E66K(Based on UniProt and PDB) => M1R E3K K65I E66K\n",
    "    row[\"mutation_sequence_code\"] = row[\"MUTATION\"].split('(')[0]\n",
    "    \n",
    "    # we only need first char of mutated_chain\n",
    "    row[\"mutated_chain\"] = row[\"mutated_chain\"][0] if row[\"mutated_chain\"] else \"\"\n",
    "    # remove last space in str\n",
    "    row[\"mutation_code\"] = row[\"mutation_code\"].strip()\n",
    "    row[\"mutation_sequence_code\"] = row[\"mutation_sequence_code\"].strip()\n",
    "    # remove spaces in some uniprot id:\n",
    "    row[\"uniprot\"] = row[\"uniprot\"].replace(\" \", \"\")\n",
    "\n",
    "    return row\n",
    "\n",
    "prothermdb_df = prothermdb_df.apply(process_prothermdb, axis=1)\n",
    "\n",
    "prothermdb_df.drop(columns=['NO','KEY_WORDS', 'REFERENCE', 'AUTHOR', 'REMARKS', 'RELATED_ENTRIES', \"MUTATION\", \"PDB_Chain_Mutation\"],\n",
    "                    inplace=True)\n",
    "\n",
    "prothermdb_df = prothermdb_df[COLUMNS+(list(set(prothermdb_df.columns.to_list())-set(COLUMNS)))]\n",
    "save_df(prothermdb_df, \"prothermdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# - check for multiple mutations : how to handle ?\n",
    "# - careful sometimes '-' instead of NaN/empty"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('novozymes-prediction-Gl9CRTFV')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "27b13dc4add9efa918e6bb920c50afa2240557655d90455391ab57f21c65447b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
