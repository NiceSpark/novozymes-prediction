{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take tmp_pdb_uniprot_db.csv and add the uniprot ids and infos when missing\n",
    "\n",
    "1st step: merge row together (only 1 row for each (pdb,uniprot) tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import pypdb\n",
    "import urllib.request\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS=['uniprot', 'PDB_wild', 'sequence', 'length', 'molWeight', 'countByFeatureType', 'chain_start', 'chain_end']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_to_pdb(seq):\n",
    "    # get pdb id from protein sequence using the pypdb package to query the RCSB Protein Data Bank API\n",
    "    q = pypdb.Query(seq, \n",
    "        query_type=\"sequence\", \n",
    "        return_type=\"polymer_entity\")\n",
    "    \n",
    "    for result in q.search()[\"result_set\"]:\n",
    "        [result_id, chain] = result[\"identifier\"].split('_')\n",
    "        if result[\"score\"] == 1.0 and chain==\"1\":\n",
    "            return result_id\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "def uniprotid_to_infos(uniprotid, pdb_ids=False):\n",
    "    try:\n",
    "        with urllib.request.urlopen(f\"https://rest.uniprot.org/uniprotkb/{uniprotid}.json\") as url:\n",
    "            data = json.load(url)\n",
    "    except Exception as e:\n",
    "        print(f\"exception raised for {uniprotid}: {e}\")\n",
    "        return {}\n",
    "\n",
    "    databases = data.get(\"uniProtKBCrossReferences\", [])\n",
    "\n",
    "    # if we only want the pdb_ids return it immediately\n",
    "    if pdb_ids:\n",
    "        pdb_ids = \" \".join([x[\"id\"] for x in databases if (x[\"database\"]==\"PDB\")])\n",
    "        return {\"PDB_wild\": pdb_ids}\n",
    "    \n",
    "    features = data.get(\"features\", [])\n",
    "    chain_location = next((x for x in features if x[\"type\"]==\"Chain\"), {}).get(\"location\", {})\n",
    "    return {\n",
    "        \"sequence\": data.get(\"sequence\", {}).get(\"value\"),\n",
    "        \"length\": data.get(\"sequence\", {}).get(\"length\"),\n",
    "        \"molWeight\": data.get(\"sequence\", {}).get(\"molWeight\"),\n",
    "        # \"countByFeatureType\": data.get(\"extraAttributes\", {}).get(\"countByFeatureType\"), \n",
    "        \"chain_start\": chain_location.get(\"start\", {}).get(\"value\"),\n",
    "        \"chain_end\": chain_location.get(\"end\", {}).get(\"value\"),\n",
    "        \"AlphaFoldDB\": \" \".join([x[\"id\"] for x in databases if (x[\"database\"]==\"AlphaFoldDB\")])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/main_dataset/tmp_pdb_uniprot_db.csv\")\n",
    "df = df[[\"uniprot\", \"PDB_wild\"]]\n",
    "df[\"PDB_wild\"] = df[\"PDB_wild\"].apply(lambda x: str(x).upper())\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_function(l):\n",
    "    unique_l = set([str(x) for x in l if (x and str(x)!='nan')])\n",
    "    return \" \".join(unique_l)\n",
    "\n",
    "df2 = df.groupby(\"PDB_wild\", as_index=False).agg({\"uniprot\": agg_function})\n",
    "print(len(df2))\n",
    "\n",
    "\n",
    "#### MULTIPLE ids ####\n",
    "def duplicate_multiple_ids_row(df, sep, multiple_col, unique_id_col):\n",
    "    multiple_ids = df[multiple_col].str.contains(sep, case=False)\n",
    "    multiple_ids_df = pd.DataFrame()\n",
    "    for _, row in df.loc[multiple_ids].iterrows():\n",
    "        ids = row[multiple_col].split(sep)\n",
    "        additional_rows = pd.DataFrame({unique_id_col: [row[unique_id_col] if row[unique_id_col] != \"NAN\" else \"\"]*len(ids),\n",
    "                                        multiple_col: ids\n",
    "                                        }, columns=df.columns)\n",
    "        multiple_ids_df = pd.concat([multiple_ids_df, additional_rows], ignore_index=True)\n",
    "\n",
    "    df = df.loc[~multiple_ids]\n",
    "    df = pd.concat([df, multiple_ids_df], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "# (X,P00644 P00645) => (X, P00644), (X, P00645)\n",
    "# add rows when there are multiple uniprot id for 1 pdb id\n",
    "df2 = duplicate_multiple_ids_row(df2, \" \", multiple_col=\"uniprot\", unique_id_col=\"PDB_wild\")\n",
    "print(len(df2))\n",
    "\n",
    "# (1SVX|3MBP,P0AEX9) => (1SVX,P0AEX9), (3MBP, P0AEX9)\n",
    "df2 = duplicate_multiple_ids_row(df2, \"|\", multiple_col=\"PDB_wild\", unique_id_col=\"uniprot\")\n",
    "print(len(df2))\n",
    "\n",
    "#### Warning ####\n",
    "# A weird bug makes it so 1E21 is converted to a number (1.00E+21) and therefor is different from the row w/ PDBwild = \"1E21\"\n",
    "# Thus we remove this first line (it exist already on line 121)\n",
    "df2 = df2.iloc[1:, :]\n",
    "\n",
    "#### Remove occurences when there is a PDB with no uniprot \n",
    "# alltough another row contains the PDB & the uniprot \n",
    "# (and vice-versa) ####\n",
    "no_uniprot = df2.uniprot.eq(\"\")\n",
    "no_uniprot_df = df2.loc[no_uniprot]\n",
    "no_uniprot_df.reset_index(inplace=True)\n",
    "df2 = df2.loc[~no_uniprot]\n",
    "\n",
    "no_pdb = df2.PDB_wild.eq(\"\")\n",
    "no_pdb_df = df2.loc[no_pdb]\n",
    "no_pdb_df.reset_index(inplace=True)\n",
    "df2 = df2.loc[~no_pdb]\n",
    "\n",
    "# df2 now consist of only rows with both pdb AND uniprot\n",
    "# uniprot:\n",
    "linked_row_found = [True]*len(no_uniprot_df)\n",
    "for index, row in no_uniprot_df.iterrows():\n",
    "    linked_row = df2.PDB_wild.eq(row.PDB_wild)\n",
    "    if linked_row.any():\n",
    "        linked_row_found[index] = False\n",
    "# we remove the rows with no_uniprot for which we found another row with both uniprot and pdb\n",
    "no_uniprot_df = no_uniprot_df[linked_row_found]\n",
    "print(f\"rm {len(linked_row_found)-len(no_uniprot_df)} rows from no_uniprot because at least 1 other row contained both information\")\n",
    "# pdb:\n",
    "linked_row_found = [True]*len(no_pdb_df)\n",
    "for index, row in no_pdb_df.iterrows():\n",
    "    linked_row = df2.uniprot.eq(row.uniprot)\n",
    "    if linked_row.any():\n",
    "        linked_row_found[index] = False\n",
    "# we remove the rows with no_pdb for which we found another row with both uniprot and pdb\n",
    "no_pdb_df = no_pdb_df[linked_row_found]\n",
    "print(f\"rm {len(linked_row_found)-len(no_pdb_df)} rows from no_pdb because at least 1 other row contained both information\")\n",
    "\n",
    "# rows with no pdb have uniprot ids, we can use uniprot DB to get possible pdb ids\n",
    "def add_pdb(row):\n",
    "    row[\"PDB_wild\"] = uniprotid_to_infos(row[\"uniprot\"], pdb_ids=True).get(\"PDB_wild\", \"\")\n",
    "    return row\n",
    "\n",
    "no_pdb_df = no_pdb_df.apply(add_pdb, axis=1)\n",
    "no_pdb_df = duplicate_multiple_ids_row(no_pdb_df, \" \", multiple_col=\"PDB_wild\", unique_id_col=\"uniprot\")\n",
    "\n",
    "\n",
    "# we add back the curated rows with no_pdb and no_uniprot\n",
    "df2 = pd.concat([df2, no_pdb_df, no_uniprot_df], ignore_index=True)\n",
    "\n",
    "print(len(df2))\n",
    "df2 = df2.drop_duplicates()\n",
    "df2.drop(columns=\"index\", inplace=True)\n",
    "print(len(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(\"./data/main_dataset/pdb_uniprot_mapping.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd step: for all unique uniprot id get all possible infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/494 [00:00<01:19,  6.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exception raised for nan: HTTP Error 400: Bad Request\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 334/494 [01:05<00:25,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exception raised for GQ884175: HTTP Error 400: Bad Request\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 494/494 [01:47<00:00,  4.61it/s]\n"
     ]
    }
   ],
   "source": [
    "# get all infos related to every uniprot id:\n",
    "df2 = pd.read_csv(\"./data/main_dataset/pdb_uniprot_db.csv\")\n",
    "all_uniprot = set(df2.uniprot.to_list()) # this gives unique values of uniprot\n",
    "uniprot_infos = []\n",
    "\n",
    "for uniprot in tqdm.tqdm(all_uniprot):\n",
    "        infos = uniprotid_to_infos(uniprot)\n",
    "        infos[\"uniprot\"] = uniprot\n",
    "        uniprot_infos.append(infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniprot</th>\n",
       "      <th>sequence</th>\n",
       "      <th>length</th>\n",
       "      <th>molWeight</th>\n",
       "      <th>countByFeatureType</th>\n",
       "      <th>chain_start</th>\n",
       "      <th>chain_end</th>\n",
       "      <th>AlphaFoldDB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P07170</td>\n",
       "      <td>MSSSESIRMVLIGPPGAGKGTQAPNLQERFHAAHLATGDMLRSQIA...</td>\n",
       "      <td>222.0</td>\n",
       "      <td>24255.0</td>\n",
       "      <td>{'Initiator methionine': 1, 'Propeptide': 1, '...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>P07170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P30289</td>\n",
       "      <td>MRIPPRLVALAGAAAVAATLIAGPVAAAAPASHAVAASSAASASVK...</td>\n",
       "      <td>141.0</td>\n",
       "      <td>14820.0</td>\n",
       "      <td>{'Signal': 1, 'Chain': 1, 'Active site': 2, 'D...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>P30289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P0AA04</td>\n",
       "      <td>MFQQEVTITAPNGLHTRPAAQFVKEAKGFTSEITVTSNGKSASAKS...</td>\n",
       "      <td>85.0</td>\n",
       "      <td>9119.0</td>\n",
       "      <td>{'Chain': 1, 'Domain': 1, 'Active site': 1, 'B...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>P0AA04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P06312</td>\n",
       "      <td>MVLQTQVFISLLLWISGAYGDIVMTQSPDSLAVSLGERATINCKSS...</td>\n",
       "      <td>121.0</td>\n",
       "      <td>13380.0</td>\n",
       "      <td>{'Signal': 1, 'Chain': 1, 'Domain': 1, 'Region...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>P06312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P00094</td>\n",
       "      <td>MKISLTAATVAALVLAAPAFAGDAAKGEKEFNKCKTCHSIIAPDGT...</td>\n",
       "      <td>137.0</td>\n",
       "      <td>14279.0</td>\n",
       "      <td>{'Signal': 1, 'Chain': 1, 'Binding site': 4, '...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>P00094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  uniprot                                           sequence  length  \\\n",
       "1  P07170  MSSSESIRMVLIGPPGAGKGTQAPNLQERFHAAHLATGDMLRSQIA...   222.0   \n",
       "2  P30289  MRIPPRLVALAGAAAVAATLIAGPVAAAAPASHAVAASSAASASVK...   141.0   \n",
       "3  P0AA04  MFQQEVTITAPNGLHTRPAAQFVKEAKGFTSEITVTSNGKSASAKS...    85.0   \n",
       "4  P06312  MVLQTQVFISLLLWISGAYGDIVMTQSPDSLAVSLGERATINCKSS...   121.0   \n",
       "5  P00094  MKISLTAATVAALVLAAPAFAGDAAKGEKEFNKCKTCHSIIAPDGT...   137.0   \n",
       "\n",
       "   molWeight                                 countByFeatureType  chain_start  \\\n",
       "1    24255.0  {'Initiator methionine': 1, 'Propeptide': 1, '...          3.0   \n",
       "2    14820.0  {'Signal': 1, 'Chain': 1, 'Active site': 2, 'D...         37.0   \n",
       "3     9119.0  {'Chain': 1, 'Domain': 1, 'Active site': 1, 'B...          1.0   \n",
       "4    13380.0  {'Signal': 1, 'Chain': 1, 'Domain': 1, 'Region...         21.0   \n",
       "5    14279.0  {'Signal': 1, 'Chain': 1, 'Binding site': 4, '...         22.0   \n",
       "\n",
       "   chain_end AlphaFoldDB  \n",
       "1      222.0      P07170  \n",
       "2      141.0      P30289  \n",
       "3       85.0      P0AA04  \n",
       "4      121.0      P06312  \n",
       "5      137.0      P00094  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniprot_infos_df = pd.DataFrame(uniprot_infos)\n",
    "uniprot_infos_df = uniprot_infos_df[~uniprot_infos_df.uniprot.isna()]\n",
    "\n",
    "# all numerical columns are float, because there are some NaNs\n",
    "uniprot_infos_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniprot_infos_df.to_csv(\"./data/main_dataset/uniprot_infos.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check this: (from kaggle notebook)\n",
    "```\n",
    "xml_data = json.loads(json.dumps(xmltodict.parse(requests.get(f\"https://www.ebi.ac.uk/proteins/api/proteins/pdb:{pdb_id}\").content.decode('utf-8'))))\n",
    "try:\n",
    "    protein_data = xml_data[\"uniprot\"][\"entry\"][\"protein\"]\n",
    "except:\n",
    "    return manual_map[pdb_id]\n",
    "\n",
    "try:    \n",
    "    return protein_data[\"recommendedName\"][\"fullName\"][\"#text\"]\n",
    "except:\n",
    "    try:\n",
    "        return protein_data['recommendedName']['fullName']\n",
    "    except:\n",
    "        try:\n",
    "            return protein_data[\"submittedName\"][\"fullName\"][\"#text\"]\n",
    "        except:\n",
    "            print(\"failed: \\n\", protein_data)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('novozymes-prediction-Gl9CRTFV')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "27b13dc4add9efa918e6bb920c50afa2240557655d90455391ab57f21c65447b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
